import{s as ut,b as Ms,e as Zs,n as gt}from"../chunks/scheduler.XaMymNDc.js";import{S as vt,i as dt,c as at,a as et,m as nt,t as lt,e as it,g as pt,h as n,s as p,n as _s,H as J,j as l,k as r,b as m,o as y,p as ws,u as O,f as a,l as D,d as e,r as f}from"../chunks/index.ozEcCyBp.js";import{g as ft,a as st}from"../chunks/spread.CgU5AtxT.js";import{B as yt}from"../chunks/blog.DeizYLqS.js";import{R as bt}from"../chunks/resources.BCuSXwzh.js";function xt(j){let i,d="<b>Thomas Dooms</b>, Daniel Wilhelm",g,c,o="",h,v,V,b,Ps="Background",K,x,Es=`Sparse auto-encoders have become the main focus of mechinterp research; they provide a means to extract interpretable bases from intermediate stages of the model.
They achieve this by locally reconstructing activations. While this has been remarkably effective, this has some suboptimal side-effects, in this paper we focus on distribution-dependent features.
We explain why these arise and propose a technique to separate some of them from the main reconstruction.`,Q,_,Ss="Motivation",X,w,Hs="The motivation for this work can be framed from multiple perspectives. Initially, it arose form spending quite a bit of time on Neuronpedia and seeing that the vast majority of features is token-based instead of context-based. From a training perspective, this makes sense due to the following two facts:",Y,k,Ws="<li>Token directions are generally the most important direction in the representation.</li> <li>Token directions are more frequent than some specific context-based representation.</li>",Z,C,Ls="Regardless of the reason they exist, ideally, they wouldn’t clutter the (generally limited) learned features.",ss,z,As="Method",ts,u,ks,I,as,mt='<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>t</mi></mrow><annotation encoding="application/x-tex">t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6151em;"></span><span class="mord mathnormal">t</span></span></span></span>',Cs,R,es,rt='<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">x_t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>',zs,B,ns,ot='<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>σ</mi></mrow><annotation encoding="application/x-tex">\\sigma</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">σ</span></span></span></span>',Ts,ls,F,G,is,ct='<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>a</mi><mi>t</mi></msub><mo>=</mo><mi>σ</mi><mo stretchy="false">(</mo><msub><mi>W</mi><mrow><mi>e</mi><mi>n</mi><mi>c</mi></mrow></msub><mo stretchy="false">(</mo><msub><mi>x</mi><mi>t</mi></msub><mo>−</mo><msub><mi>b</mi><mrow><mi>d</mi><mi>e</mi><mi>c</mi></mrow></msub><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">a_t = \\sigma(W_{enc}(x_t - b_{dec}))</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">σ</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">n</span><span class="mord mathnormal mtight">c</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="mord mathnormal mtight">ec</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">))</span></span></span></span>',ps,N,U,ms,ht='<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mover accent="true"><mi>x</mi><mo>^</mo></mover><mi>t</mi></msub><mo>=</mo><msub><mi>W</mi><mrow><mi>d</mi><mi>e</mi><mi>c</mi></mrow></msub><mo stretchy="false">(</mo><msub><mi>a</mi><mi>t</mi></msub><mo stretchy="false">)</mo><mo>+</mo><msub><mi>b</mi><mrow><mi>d</mi><mi>e</mi><mi>c</mi></mrow></msub><mo>+</mo><mrow><msub><mi mathvariant="bold">W</mi><mrow><mi mathvariant="bold">l</mi><mi mathvariant="bold">o</mi><mi mathvariant="bold">o</mi><mi mathvariant="bold">k</mi><mi mathvariant="bold">u</mi><mi mathvariant="bold">p</mi></mrow></msub><mo stretchy="false">(</mo><mi mathvariant="bold">t</mi><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">\\hat{x}_t = W_{dec}(a_t) + b_{dec} + \\mathbf{W_{lookup}(t)}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6944em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal">x</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.2222em;"><span class="mord">^</span></span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="mord mathnormal mtight">ec</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.8444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="mord mathnormal mtight">ec</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.0361em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord"><span class="mord mathbf" style="margin-right:0.01597em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.016em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathbf mtight">lookup</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathbf">t</span><span class="mclose">)</span></span></span></span></span>',rs,T,$s="There are some slight caveats to training this lookup table, which are described in the paper. Outside of this, it’s really just that simple.",os,M,qs="Results",cs,P,js="We show adding a lookup table improves the final reconstructions by a significant margin on GPT-2 layer 8.",hs,E,Is='<img src="/research/tokenized/pareto_nmse.svg" alt="Pareto curve of the normalized mean squared error"/> <figcaption>Pareto curve of the normalized mean squared error</figcaption>',us,S,Rs=`Beyond this, by forcing the SAE to use directions we know to be useful, it is able to learn much more quickly.
We measure how much faster TSAEs reach the final reconstruction value of their baseline variant.`,gs,H,Bs='<img src="/research/tokenized/speedup_gpt2.svg" alt="Speedup of TSAE vs baseline"/> <figcaption>Speedup of TSAE vs baseline on GPT-2 small</figcaption>',vs,W,Fs=`This huge speedup results in TSAEs reaching really high fidelity reconstructions in only a few minutes across GPT-2 layers.
We believe this will be really useful for quickly iterating on SAE suites.`,ds,L,Gs=`Common intuition is that this lookup table would become less effective with depth or model complexity.
However, our results show that Tokenized SAEs remain effective on Pythia 1.4B, even at layer 20.
We again show the speedup.`,fs,A,Ns='<img src="/research/tokenized/speedup_pythia.svg" alt="Speedup of TSAE vs baseline"/> <figcaption>Speedup of TSAE vs baseline on Pythia 1.4B</figcaption>',ys,$,Us="Future Work",bs,q,Ds="The general idea of incorporating inductive bias into SAEs seems interesting to pursue. Trivially, a more general (sparse) n-gram lookup table could be used. Furthermore, features from a preceding SAE could similarly be used into some kind of lookup table.",xs;return v=new bt({props:{paper:"https://openreview.net/attachment?id=5Eas7HCe38&name=pdf"}}),{c(){i=n("p"),i.innerHTML=d,g=p(),c=n("div"),c.innerHTML=o,h=p(),at(v.$$.fragment),V=p(),b=n("h3"),b.textContent=Ps,K=p(),x=n("p"),x.textContent=Es,Q=p(),_=n("h3"),_.textContent=Ss,X=p(),w=n("p"),w.textContent=Hs,Y=p(),k=n("ul"),k.innerHTML=Ws,Z=p(),C=n("p"),C.textContent=Ls,ss=p(),z=n("h3"),z.textContent=As,ts=p(),u=n("p"),ks=_s(`I generally introduce the proposed method as a simple trick to remove these single-token features which seems to work surprisingly well.
The main idea is to introduce a lookup table to the decoder that is indexed by the original token of the current activations.
This table then takes care of the “base” reconstruction for each token.
We denote the hidden activations that originate from some token `),I=n("span"),as=new J(!1),Cs=_s(" as "),R=n("span"),es=new J(!1),zs=_s(" and the sparsity/activation function as "),B=n("span"),ns=new J(!1),Ts=_s("."),ls=p(),F=n("p"),G=n("span"),is=new J(!1),ps=p(),N=n("p"),U=n("span"),ms=new J(!1),rs=p(),T=n("p"),T.textContent=$s,os=p(),M=n("h3"),M.textContent=qs,cs=p(),P=n("p"),P.textContent=js,hs=p(),E=n("figure"),E.innerHTML=Is,us=p(),S=n("p"),S.textContent=Rs,gs=p(),H=n("figure"),H.innerHTML=Bs,vs=p(),W=n("p"),W.textContent=Fs,ds=p(),L=n("p"),L.textContent=Gs,fs=p(),A=n("figure"),A.innerHTML=Ns,ys=p(),$=n("h3"),$.textContent=Us,bs=p(),q=n("p"),q.textContent=Ds,this.h()},l(s){i=l(s,"P",{"data-svelte-h":!0}),r(i)!=="svelte-8oxhqk"&&(i.innerHTML=d),g=m(s),c=l(s,"DIV",{class:!0,"data-svelte-h":!0}),r(c)!=="svelte-wdfy0z"&&(c.innerHTML=o),h=m(s),et(v.$$.fragment,s),V=m(s),b=l(s,"H3",{"data-svelte-h":!0}),r(b)!=="svelte-1q8ftns"&&(b.textContent=Ps),K=m(s),x=l(s,"P",{"data-svelte-h":!0}),r(x)!=="svelte-8pic1r"&&(x.textContent=Es),Q=m(s),_=l(s,"H3",{"data-svelte-h":!0}),r(_)!=="svelte-ovad3o"&&(_.textContent=Ss),X=m(s),w=l(s,"P",{"data-svelte-h":!0}),r(w)!=="svelte-cit4wd"&&(w.textContent=Hs),Y=m(s),k=l(s,"UL",{"data-svelte-h":!0}),r(k)!=="svelte-1cfrhwp"&&(k.innerHTML=Ws),Z=m(s),C=l(s,"P",{"data-svelte-h":!0}),r(C)!=="svelte-1c8gzn"&&(C.textContent=Ls),ss=m(s),z=l(s,"H3",{"data-svelte-h":!0}),r(z)!=="svelte-6xa91h"&&(z.textContent=As),ts=m(s),u=l(s,"P",{});var t=y(u);ks=ws(t,`I generally introduce the proposed method as a simple trick to remove these single-token features which seems to work surprisingly well.
The main idea is to introduce a lookup table to the decoder that is indexed by the original token of the current activations.
This table then takes care of the “base” reconstruction for each token.
We denote the hidden activations that originate from some token `),I=l(t,"SPAN",{class:!0});var Js=y(I);as=O(Js,!1),Js.forEach(a),Cs=ws(t," as "),R=l(t,"SPAN",{class:!0});var Os=y(R);es=O(Os,!1),Os.forEach(a),zs=ws(t," and the sparsity/activation function as "),B=l(t,"SPAN",{class:!0});var Vs=y(B);ns=O(Vs,!1),Vs.forEach(a),Ts=ws(t,"."),t.forEach(a),ls=m(s),F=l(s,"P",{});var Ks=y(F);G=l(Ks,"SPAN",{class:!0});var Qs=y(G);is=O(Qs,!1),Qs.forEach(a),Ks.forEach(a),ps=m(s),N=l(s,"P",{});var Xs=y(N);U=l(Xs,"SPAN",{class:!0});var Ys=y(U);ms=O(Ys,!1),Ys.forEach(a),Xs.forEach(a),rs=m(s),T=l(s,"P",{"data-svelte-h":!0}),r(T)!=="svelte-baox7a"&&(T.textContent=$s),os=m(s),M=l(s,"H3",{"data-svelte-h":!0}),r(M)!=="svelte-do08fc"&&(M.textContent=qs),cs=m(s),P=l(s,"P",{"data-svelte-h":!0}),r(P)!=="svelte-1dhjp47"&&(P.textContent=js),hs=m(s),E=l(s,"FIGURE",{"data-svelte-h":!0}),r(E)!=="svelte-13i6uh8"&&(E.innerHTML=Is),us=m(s),S=l(s,"P",{"data-svelte-h":!0}),r(S)!=="svelte-1tudezn"&&(S.textContent=Rs),gs=m(s),H=l(s,"FIGURE",{"data-svelte-h":!0}),r(H)!=="svelte-19wsk3t"&&(H.innerHTML=Bs),vs=m(s),W=l(s,"P",{"data-svelte-h":!0}),r(W)!=="svelte-gkbjnu"&&(W.textContent=Fs),ds=m(s),L=l(s,"P",{"data-svelte-h":!0}),r(L)!=="svelte-1ekgj3d"&&(L.textContent=Gs),fs=m(s),A=l(s,"FIGURE",{"data-svelte-h":!0}),r(A)!=="svelte-1d52r7y"&&(A.innerHTML=Ns),ys=m(s),$=l(s,"H3",{"data-svelte-h":!0}),r($)!=="svelte-1r68seq"&&($.textContent=Us),bs=m(s),q=l(s,"P",{"data-svelte-h":!0}),r(q)!=="svelte-1iobtph"&&(q.textContent=Ds),this.h()},h(){D(c,"class","mt-6"),as.a=null,D(I,"class","math math-inline"),es.a=null,D(R,"class","math math-inline"),ns.a=null,D(B,"class","math math-inline"),is.a=null,D(G,"class","math math-inline"),ms.a=null,D(U,"class","math math-inline")},m(s,t){e(s,i,t),e(s,g,t),e(s,c,t),e(s,h,t),nt(v,s,t),e(s,V,t),e(s,b,t),e(s,K,t),e(s,x,t),e(s,Q,t),e(s,_,t),e(s,X,t),e(s,w,t),e(s,Y,t),e(s,k,t),e(s,Z,t),e(s,C,t),e(s,ss,t),e(s,z,t),e(s,ts,t),e(s,u,t),f(u,ks),f(u,I),as.m(mt,I),f(u,Cs),f(u,R),es.m(rt,R),f(u,zs),f(u,B),ns.m(ot,B),f(u,Ts),e(s,ls,t),e(s,F,t),f(F,G),is.m(ct,G),e(s,ps,t),e(s,N,t),f(N,U),ms.m(ht,U),e(s,rs,t),e(s,T,t),e(s,os,t),e(s,M,t),e(s,cs,t),e(s,P,t),e(s,hs,t),e(s,E,t),e(s,us,t),e(s,S,t),e(s,gs,t),e(s,H,t),e(s,vs,t),e(s,W,t),e(s,ds,t),e(s,L,t),e(s,fs,t),e(s,A,t),e(s,ys,t),e(s,$,t),e(s,bs,t),e(s,q,t),xs=!0},p:gt,i(s){xs||(lt(v.$$.fragment,s),xs=!0)},o(s){it(v.$$.fragment,s),xs=!1},d(s){s&&(a(i),a(g),a(c),a(h),a(V),a(b),a(K),a(x),a(Q),a(_),a(X),a(w),a(Y),a(k),a(Z),a(C),a(ss),a(z),a(ts),a(u),a(ls),a(F),a(ps),a(N),a(rs),a(T),a(os),a(M),a(cs),a(P),a(hs),a(E),a(us),a(S),a(gs),a(H),a(vs),a(W),a(ds),a(L),a(fs),a(A),a(ys),a($),a(bs),a(q)),pt(v,s)}}}function _t(j){let i,d;const g=[j[0],tt];let c={$$slots:{default:[xt]},$$scope:{ctx:j}};for(let o=0;o<g.length;o+=1)c=Ms(c,g[o]);return i=new yt({props:c}),{c(){at(i.$$.fragment)},l(o){et(i.$$.fragment,o)},m(o,h){nt(i,o,h),d=!0},p(o,[h]){const v=h&1?ft(g,[h&1&&st(o[0]),h&0&&st(tt)]):{};h&2&&(v.$$scope={dirty:h,ctx:o}),i.$set(v)},i(o){d||(lt(i.$$.fragment,o),d=!0)},o(o){it(i.$$.fragment,o),d=!1},d(o){pt(i,o)}}}const tt={title:"Tokenized SAEs",date:"18 Jul 2024",kind:"research"};function wt(j,i,d){return j.$$set=g=>{d(0,i=Ms(Ms({},i),Zs(g)))},i=Zs(i),[i]}class Pt extends vt{constructor(i){super(),dt(this,i,wt,_t,ut,{})}}export{Pt as component};
