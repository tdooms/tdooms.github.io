<!doctype html>
<html lang="en">
	<head>
		<meta charset="utf-8" />
		<link rel="icon" href="../favicon.png" />

		<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css" crossorigin="anonymous">

		<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/all.min.css" />
		<link rel="stylesheet" href="../styles.css" />

		<!-- slight hack for blogs -->
		<style>
			.content h6 { margin-bottom: 0 !important; }
		</style>

		<meta name="viewport" content="width=device-width, initial-scale=1" />
		
		<link rel="modulepreload" href="../_app/immutable/entry/start.DOTjlLkP.js">
		<link rel="modulepreload" href="../_app/immutable/chunks/entry.pnQ-aq7J.js">
		<link rel="modulepreload" href="../_app/immutable/chunks/scheduler.Dre08-OG.js">
		<link rel="modulepreload" href="../_app/immutable/entry/app.DkgqmrYX.js">
		<link rel="modulepreload" href="../_app/immutable/chunks/index.KEXCFnl8.js">
		<link rel="modulepreload" href="../_app/immutable/nodes/0.CP36r_sj.js">
		<link rel="modulepreload" href="../_app/immutable/nodes/4.C68qX5D8.js">
		<link rel="modulepreload" href="../_app/immutable/chunks/navbar.Dq_HBQv8.js">
		<link rel="modulepreload" href="../_app/immutable/nodes/14.CUqt_V-U.js">
		<link rel="modulepreload" href="../_app/immutable/chunks/spread.CgU5AtxT.js">
		<link rel="modulepreload" href="../_app/immutable/chunks/blog.ZySM1lpf.js">
		<link rel="modulepreload" href="../_app/immutable/chunks/resources.fSw4pCni.js">
	</head>
	<body data-sveltekit-preload-data="hover">
		<div style="display: contents">  <main class="container mt-5"><div class="columns"><div class="column"><div class="tabs is-boxed is-right"><ul><li class=""><a href="/blog" data-svelte-h="svelte-1pkmwhq"><span class="icon is-small"><i class="fas fa-fire" aria-hidden="true"></i></span> <span>Blog</span></a></li> <li class="is-active"><a href="/research" data-svelte-h="svelte-axh4gx"><span class="icon is-small"><i class="fas fa-atom" aria-hidden="true"></i></span> <span>Research</span></a></li></ul></div></div> <div class="column is-narrow"><a href="."><b style="font-weight: 800" class="title is-3">tdooms</b></a></div> <div class="column"><div class="tabs is-boxed is-left"><ul><li class=""><a href="/projects" data-svelte-h="svelte-lnjikn"><span class="icon is-small"><i class="fas fa-code" aria-hidden="true"></i></span> <span>Projects</span></a></li> <li class=""><a href="/resume" data-svelte-h="svelte-d2d5v"><span class="icon is-small"><i class="far fa-file-alt" aria-hidden="true"></i></span> <span>Resume</span></a></li></ul></div></div></div> <div class="content has-text-justified" style="margin: 0 auto;max-width: 880px;"> <div class="columns mb-0"><div class="column has-text-left"><h2 class="title is-2 mb-0">Bilinear Decomposition</h2></div> <div class="column is-narrow has-text-right"><h6 class="title is-6 mt-5">18 Jul 2024</h6></div></div> <p data-svelte-h="svelte-1p7kwfh">Michael T. Pearce, <b>Thomas Dooms</b>, Alice Rigg</p> <div class="mt-6" data-svelte-h="svelte-wdfy0z"></div> <div class="columns is-centered"><div class="column is-2 px-3"><a class="box has-text-centered" href="https://arxiv.org/abs/2406.03947" target="_blank"><span class="icon is-large" data-svelte-h="svelte-1016q84"><i class="fa-regular fa-xl fa-file"></i></span> <p data-svelte-h="svelte-v0we3a">Paper</p></a></div> <div class="column is-2"><a class="box has-text-centered" href="https://github.com/tdooms/bilinear-decomposition" target="_blank"><span class="icon is-large" data-svelte-h="svelte-1j6hihf"><i class="fa-brands fa-xl fa-github"></i></span> <p data-svelte-h="svelte-v8f87x">Code</p></a></div> <div class="column is-2"><a class="box has-text-centered" href="https://huggingface.co/collections/tdooms/bilinear-66991d82406db9529a7170d2" target="_blank"><span class="icon is-large" data-svelte-h="svelte-6sjg4"><i class="fa-solid fa-xl fa-database"></i></span> <p data-svelte-h="svelte-1u0d79u">Models</p></a></div></div> <h3 data-svelte-h="svelte-1q8ftns">Background</h3> <p data-svelte-h="svelte-tzl0b3">Understanding models from their weights has long been a pipedream of many interpretability researchers.
The main obstacle to this is that ReLUs (or non-linear activation functions in general) are not meaningful without inputs.
Since, any small change in input can cause a ReLU to “activate”.
The <em>only</em> way to compute the output of a ReLU is to actually provide it an input and just see what happens.
This has made it notoriously hard to put any form of guarantees on model behaviour and has led to a plethora of input-dependent research in the past.
The one thing giving rise to the astounding capabilities is also the thing that makes them <em>really</em> hard to study.</p> <p data-svelte-h="svelte-2f7l7x">Bilinear layers, may be able to offer us the best of both worlds; weights which we can meaningfully study while retaining the current capabilities.
Bilinear layers are part of the gated linear unit (GLU) family, which are gaining lots of traction due to their accuracy benefits recently.
The bilinear layer is the simplest form of a GLU, using no activation function at all.
One prominent question that is often asked at this point is “if this is just doing linear operations, how can this be a good model component”?
While either side <em>is</em> linear, the whole is bilinear, which is non-linear to the input, which is all we need.</p> <div class="columns is-centered" data-svelte-h="svelte-1ks8fi9"><div class="column is-narrow"><figure><img src="/research/bilinear/glu.svg" alt="GLU & Bilinear"> <figcaption>An ordinary GLU (left) and a bilinear layer (right). An ordinary GLU has a gate part which &quot;selects&quot; <br> which parts of the other side should be kept.
        In the case of a bilinear layer, this selection is instead continuous.</figcaption></figure></div></div> <p data-svelte-h="svelte-n9pg3x">As foreshadowed, the linearity of each branch is a really useful for interpretability. It allows to use techniques from linear algebra such as SVD and have them actually be meaningful. However, that’s not all, each output of a bilinear layer can be described quite elegantly; it’s a sum of (weighted) pairwise input feature interactions. Note that this is impossible to do for a layer with a ReLU (or other activation functions), there is no clean formula that describes how features interact.</p> <h3 data-svelte-h="svelte-15y9o0a">Decomposing The Weights</h3> <p data-svelte-h="svelte-3ulqu2">We can exploit all these facts to find useful direction for each output of such a layer.
While we won’t go into details, these are the main ideaas behind the decomposition.</p> <ol><li><p>The feature interactions of a bilinear layer output can be written as <span class="math math-inline"><!-- HTML_TAG_START --><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext mathvariant="bold">x</mtext><mi>A</mi><mtext mathvariant="bold">x</mtext></mrow><annotation encoding="application/x-tex">\textbf{x}A\textbf{x}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord text"><span class="mord textbf">x</span></span><span class="mord mathnormal">A</span><span class="mord text"><span class="mord textbf">x</span></span></span></span></span><!-- HTML_TAG_END --></span> where we call <span class="math math-inline"><!-- HTML_TAG_START --><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal">A</span></span></span></span><!-- HTML_TAG_END --></span> the interaction matrix. Each entry in the matrix is the weight of how strong the feature at the row and column should interact. Due to this structure, it is a symmetric matrix. While this is nice, this interaction matrix is hard to visualize for any non-trivial problem (especially if the features are structured, such as images).</p></li> <li><p>Luckily, we can leverage this symmetric property and perform an eigendecomposition on these matrices. This operation decomposes the matrix into <span class="math math-inline"><!-- HTML_TAG_START --><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mo>∑</mo><mi>i</mi></msub><msub><mi>λ</mi><mi>i</mi></msub><msub><mi>v</mi><mi>i</mi></msub><mo>⊗</mo><msub><mi>v</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">\sum_i \lambda_i v_i \otimes v_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0497em;vertical-align:-0.2997em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:0em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.162em;"><span style="top:-2.4003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2997em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">λ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">⊗</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span><!-- HTML_TAG_END --></span> (where <span class="math math-inline"><!-- HTML_TAG_START --><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>⊗</mo></mrow><annotation encoding="application/x-tex">\otimes</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6667em;vertical-align:-0.0833em;"></span><span class="mord">⊗</span></span></span></span><!-- HTML_TAG_END --></span> is an outer product) where values of <span class="math math-inline"><!-- HTML_TAG_START --><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>λ</mi></mrow><annotation encoding="application/x-tex">\lambda</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal">λ</span></span></span></span><!-- HTML_TAG_END --></span> decrease. In words, this finds which vectors best describe the interaction matrix. We can then easily visualize these vectors.</p></li> <li data-svelte-h="svelte-1xlpf8v"><p>Since a sum of symmetric matrices is still symmetric, this can be done for any output direction not just single outputs. For instance, we can take the difference between two features by subtracting the interaction matrices.</p></li></ol> <p data-svelte-h="svelte-qh21fd">The following images depict the most important eigenvector for a set of digits in a single-layer MNIST model.</p> <div class="columns" data-svelte-h="svelte-zanb88"><div class="column"><img src="/research/bilinear/digit_0.svg" alt="digit 0"></div> <div class="column"><img src="/research/bilinear/digit_1.svg" alt="digit 1"></div> <div class="column"><img src="/research/bilinear/digit_5.svg" alt="digit 5"></div> <div class="column"><img src="/research/bilinear/digit_6.svg" alt="digit 6"></div></div> <p data-svelte-h="svelte-1nvlwio">This shows that exploiting these properties of the bilinear layer can yield very interpretable structure from the weights alone!</p> <h3 data-svelte-h="svelte-53090i">Language Models</h3> <p data-svelte-h="svelte-1fiaazj">We can use the same technique of replacing MLPs in a transformer with its bilinear variant.
This allows us to understand the computation going on in MLPs on a deep level.</p> <p data-svelte-h="svelte-o6ph00">The following figure specifically extends the technique to attention, we derive the most important features for swim and then examine which samples activate them most strongly.
We see that the first feature fires on sea related contexts while the second is mostly grammatical.</p> <figure data-svelte-h="svelte-pftcks"><img src="/research/bilinear/swim-cropped.svg" alt="Eigenvectors of swim" width="880"> <figcaption></figcaption></figure> <h3 data-svelte-h="svelte-1r68seq">Future Work</h3> <p data-svelte-h="svelte-1ieuwrf">Currently, this approach is only feasible on shallow models as the number of eigenvectors grows exponentially with layer size.
We are exploring techniques to reduce this.</p> <p data-svelte-h="svelte-k328po">This work mostly aimed to show the interpretability instead of leveraging the decomposition towards concrete findings.
One could imagine using this to uncover induction behaviour in language models or curve detector circuits in vision models in a principled manner.</p> <div class="card"><header class="card-header has-background-grey-light"><p class="card-header-title mb-0" data-svelte-h="svelte-1aufd48">How to cite</p> <button class="card-header-icon" aria-label="more options"><span class="icon"><i class="fa-solid fa-copy" aria-hidden="true"></i></span></button></header> <small><pre class="card-content" id="cite-slot">@misc{pearce2024weightbaseddecompositioncasebilinear,
        title={Weight-based Decomposition: A Case for Bilinear MLPs},
        author={Michael T. Pearce and Thomas Dooms and Alice Rigg},
        year={2024},
        eprint={2406.03947},
        archivePrefix={arXiv},
        primaryClass={cs.LG},
        url={https://arxiv.org/abs/2406.03947},
    }</pre></small></div> <div class="buttons is-centered mt-5"><a class="button is-primary" href="/research">Back</a></div> <div class="mb-6"></div></div></main> 
			
			<script>
				{
					__sveltekit_j38joz = {
						base: new URL("..", location).pathname.slice(0, -1)
					};

					const element = document.currentScript.parentElement;

					const data = [null,null,null];

					Promise.all([
						import("../_app/immutable/entry/start.DOTjlLkP.js"),
						import("../_app/immutable/entry/app.DkgqmrYX.js")
					]).then(([kit, app]) => {
						kit.start(app, element, {
							node_ids: [0, 4, 14],
							data,
							form: null,
							error: null
						});
					});
				}
			</script>
		</div>
	</body>
</html>
